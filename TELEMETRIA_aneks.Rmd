---
title: "Aneks - szereg czasowy oglądalności telewizji"
author: Zbigniew Marczewski
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: html_document
---

# Materiały 

[https://onlinecourses.science.psu.edu/stat510/node/47](https://onlinecourses.science.psu.edu/stat510/node/47)

__Rodzaje procesów__

[http://www.investopedia.com/articles/trading/07/stationary.asp](http://www.investopedia.com/articles/trading/07/stationary.asp)

__YouTube__

[https://www.youtube.com/watch?v=-5S-L_4GHU4](https://www.youtube.com/watch?v=-5S-L_4GHU4)


__a-little-book-of-r-for-time-series__

[https://a-little-book-of-r-for-time-series.readthedocs.io/en/latest/src/timeseries.html](https://a-little-book-of-r-for-time-series.readthedocs.io/en/latest/src/timeseries.html)

__Dekompozycja szeregu czasowego__

[https://anomaly.io/seasonal-trend-decomposition-in-r/](https://anomaly.io/seasonal-trend-decomposition-in-r/)

__Box–Jenkins__ - metoda 

[https://en.wikipedia.org/wiki/Box%E2%80%93Jenkins](https://en.wikipedia.org/wiki/Box%E2%80%93Jenkins)

# Pobieranie danych

```{r}
# setwd("C:/Users/Zbyszek/Desktop/WAS/TELEMETRIA")
library( googlesheets)
library( ggplot2)
library( reshape2)
klucz<-extract_key_from_url("https://docs.google.com/spreadsheets/d/1CwAWrns8CAgizOu4iAHIqb4ckCcDfY_8xPKYr7CAUs4/edit?usp=sharing")
skoroszyt<-gs_key(klucz, visibility = "private")
#############################
# Dane o grupie w wieku 4+
#############################
dane_4plus<-gs_read(skoroszyt, "4_plus")
dane_4plus<-as.data.frame(dane_4plus)
ndane_4plus <- melt(dane_4plus,id=c("miesiac") ) # w uzyciu paciek reshape2
ndane_4plus$variable<-as.character(ndane_4plus$variable)
colnames(ndane_4plus)<-c("miesiac", "program","ogladalnosc")
#############################
# Dane o grupie 16-49
#############################
dane_16_49<-gs_read(skoroszyt, "16-49")
dane_16_49<-as.data.frame(dane_16_49)
ndane_16_49 <- melt(dane_16_49,id=c("miesiac") )
ndane_16_49$variable<-as.character(ndane_16_49$variable)
colnames(ndane_16_49)<-c("miesiac", "program","ogladalnosc")
```

# Tworzenie wykresy dla danych o osobach w wieku 4+

```{r}
##############
## udzial w widowni
##############
png('TELEMETRIA_wykresy/4_plus_udzial.png',  res = 200, width = 20, height = 10, units = "cm") #bg = "white", 
ggplot(ndane_4plus[ grep("procent",ndane_4plus$program),], aes(x=miesiac , y=ogladalnosc, group=program, color=program))+
  geom_line()+
  theme(axis.text.x = element_text(angle = 90, hjust = 1))+
  labs(title = "Odsetek widzów w grupie 4+")
dev.off()
##############
## liczebnosc widowni
##############
png('TELEMETRIA_wykresy/4_plus_liczba.png',  res = 200, width = 20, height = 10, units = "cm") #bg = "white", 
ggplot(ndane_4plus[ !(1:dim(ndane_4plus)[1]) %in% grep("procent", ndane_4plus$program),], aes(x=miesiac , y=ogladalnosc, group=program, color=program))+
  geom_line()+
  theme(axis.text.x = element_text(angle = 90, hjust = 1))+
  labs(title = "Liczba widzów w grupie 4+")
dev.off()
##############
## ROZNICE - zmiany rok do roku i procentowe rok do roku
##############
rdane_4plus<-as.matrix(dane_4plus[, !(1:dim(dane_4plus)[2]) %in% grep("procent|miesiac", colnames(dane_4plus) )])
rdane_4plus<- data.frame(  diff( rdane_4plus ,lag = 12) / rdane_4plus[1:(dim( rdane_4plus )[1]-12) ,  ]      )
rdane_4plus$miesiac<-dane_4plus$miesiac[ (dim(dane_4plus)[1]-dim(rdane_4plus)[1]+1):dim(dane_4plus)[1]]
nrdane_4plus <- melt(rdane_4plus,id=c("miesiac") ) # zmiana postaci danych
nrdane_4plus$variable<-as.character(nrdane_4plus$variable)
colnames(nrdane_4plus)<-c("miesiac", "program","ogladalnosc")
##############
## wykres roznic
##############
png('TELEMETRIA_wykresy/4_plus_roznica.png',  res = 200, width = 20, height = 10, units = "cm") #bg = "white", 
ggplot(nrdane_4plus, aes(x=miesiac , y=ogladalnosc, group=program, color=program))+
  geom_line()+
  geom_hline(aes(yintercept=0))+
  theme(axis.text.x = element_text(angle = 90, hjust = 1))+
  labs(title = "Procentowe różnice rok do roku w grupie widzów 4+")
dev.off()
```

# Analiza danych - ogólne założenia

Celem analizy danych telemetrycznych jest:

  1. ogólny opis przebiegu zmian oglądalności wybranych programów telewizyjnych w czasie:
    a. analiza trendów
    b. analiza zmian sezonowych
  2. wykazanie, czy w ostatnim czasie (w okresie od stycznia 2016 r.) występowały istotne zmiany oglądalności wybranych programów telewizyjnych, a jeśli tak, to czy wynikają one z trendu lub zmian sezonowych, czy też trzeba przyjąć hipotezę o występoniu innego, poza czasowego czynnika.

# Analiza danych - szereg czasowy

Zebrane wyniki badań telemetrycznych pokazują jak zmieniała się wielkości widowni wybranych programów telewizyjnych w czasie. Oznacza to, że dane są uporządkowane hronologicznie. Dzięki temu możemy je traktować jako __szereg czasowy__

Dla omawianego szeregu czasowego analiza danych będzie się składała z następujących etapów:

  1. ogólny opis:
    a. opis trendu
    b. opis składnika losowego
    c. opis czynnika sezonowego
  2. opis zmian zachodzących w ostatnim czasie:
    a. sprawdzenie stacjonarności szeregu - sprawdzenie czy badany szereg czasowy jest stabilny, a więc czy jest niezależny od czasu 
    b. jeśli proces stochastyczny okaże się niestabiln to na podstawie danych przygotowany zostanie specjalny model nie tylko będzie dobrze objaśnial obserowane zmiany, ale tekże będzie stacjonarny
    c. predykcja przyszłego poziomu oglądalności przy pomocy modelu stacjonarnego
  
# Analiza danych dla grupy wiekowej 4+ 

Analiza danych skupia się na problemie oglądalności "Wiadomości" TVP. 

## 1. Prosta analiza komponentów

### Prezentacja danych 

```{r}
library(timeSeries) # pakiet do analizy szeregow czasowych
dane_4plus$czas<-gsub("/","\\-",dane_4plus$miesiac)
# na liczebnosciach Wiadomosci
dane_4plus_Wiadomosci_liczba_ts<-ts( data = dane_4plus$Wiadomosci_TVP1, start = c(2013,1), frequency = 12)
cycle( dane_4plus_Wiadomosci_liczba_ts)
aggregate( dane_4plus_Wiadomosci_liczba_ts)
time( dane_4plus_Wiadomosci_liczba_ts)
plot( dane_4plus_Wiadomosci_liczba_ts, lwd=2, main="Szacowana liczba widzów\n'Wiadomości' TVP", ylab="liczba widzów", xlab="data", ylim=c( 0, max(dane_4plus_Wiadomosci_liczba_ts)))
# points( dane_4plus_Wiadomosci_liczba_ts, pch=19)
abline( reg=lm( dane_4plus_Wiadomosci_liczba_ts~time( dane_4plus_Wiadomosci_liczba_ts) ), col="red3", lwd=2, lty = 2)
```

### Filtrowanie szeregu czasowego - wygładzanie przy pomocy średniej ruchomej


```{r}
plot( dane_4plus_Wiadomosci_liczba_ts ,type="l", ylim=c(0, max(dane_4plus_Wiadomosci_liczba_ts)), lwd=2)
# (2*a+1) - to jest podzielnik w sredniej ruchomej - dla sredniej z trzech obserwacji rowny 3 dla 5 obserwacji rowny 5 itd;  parametr "a"" decyduje o tym na ile okresow w przod i tyl siegamy srednia ruchoma; np. a=2 oznacza, ze idziemy 2 pomiary w przod i tyl - lacznie 5 obserwacji;
  a<-2
  dane_4plus_Wiadomosci_liczba_ts_filtrowanie1 <- filter(dane_4plus_Wiadomosci_liczba_ts, filter=rep(1/(2*a+1),(2*a+1))) 
  a<-4
  dane_4plus_Wiadomosci_liczba_ts_filtrowanie2 <- filter(dane_4plus_Wiadomosci_liczba_ts, filter=rep(1/(2*a+1),(2*a+1)))
  a<-5
  dane_4plus_Wiadomosci_liczba_ts_filtrowanie3 <- filter(dane_4plus_Wiadomosci_liczba_ts, filter=rep(1/(2*a+1),(2*a+1)))
lines(dane_4plus_Wiadomosci_liczba_ts_filtrowanie1,col="red", lwd=2)
lines(dane_4plus_Wiadomosci_liczba_ts_filtrowanie2,col="green", lwd=2)
lines(dane_4plus_Wiadomosci_liczba_ts_filtrowanie3,col="blue", lwd=2)
```

Ponieważ w ramach jednego okresu ("fali") mamy niewiele pomiarów, a przebieg oglądalności jest bardzo zmienny wiec srednie z 12 pomiarow (a=5) przypominaja najbardziej trend i slabo odzwierciedlaja przebieg zmiennosci - to kwestia małej "gęstości" pomiarów. I więcej obserwacji w ramach jednego okresu tym więcej obserwacji może obejmować średnia ruchoma. 


### Dekompozycja danych na 3 elementy:

  * trend
  * składniki sezonowy
  * składnik losowy

Wybrałem dekompozycję addytywna (additive model) ponieważ wydaje się, że amplituda zmian w czasie (wariancja) nie zmienia się. Gdyby rosła lepszym rozwiązaniem byłoby zastosowanie dekompozycji multiplikatywnej (multiplicative model). 

Additive:
Time series = Seasonal + Trend + Random

Multiplicative:
Time series = Trend * Seasonal *Random

Dekompozycję można przeprowadzić w R przy pomocy jednej funkcji __decompose()__

```{r trend_decimpose(), }
# decompose( dane_4plus_Wiadomosci_liczba_ts)
plot( decompose( dane_4plus_Wiadomosci_liczba_ts, type ="additive"))
# acf( dane_4plus_Wiadomosci_liczba_ts, xlim=c(1,4) , lag.max = 60)
# pacf(dane_4plus_Wiadomosci_liczba_ts, xlim=c(1,4) , lag.max = 60)
```

lub przeprowadzić ją "ręcznie" (przypominam, że jest to dekompozycja addytywna)

TREND - czyli średnia ruchoma wyznaczona przy pomocy funkcji __ma()__ (moving average) z pakiegu __forecast__

```{r trend_recznie}
library(forecast)
ma( dane_4plus_Wiadomosci_liczba_ts, order = 12 ) # argument "order" wskazuje jaki jaka jest dlugosc okresu szerego czasowego - tutaj 12 miesiecy
plot(ma( dane_4plus_Wiadomosci_liczba_ts, order = 12 ))
```

Trend można zestawić z danymi

```{r trend_recznie_zestawieni}
dane_4plus_Wiadomosci_liczba_ts_trend<-ma( dane_4plus_Wiadomosci_liczba_ts, order = 12,  centre = T )
plot(dane_4plus_Wiadomosci_liczba_ts)
lines(dane_4plus_Wiadomosci_liczba_ts_trend, lty=2, lwd=2, col="red") # trend
```

i sprawdzić czy obliczenia "ręczne" dają taki sam wynik jak przy użyciu funkcji __decompose()__

 
```{r trend_recznie_sprawdzenie}
decompose( dane_4plus_Wiadomosci_liczba_ts, type ="additive")[["trend"]] == dane_4plus_Wiadomosci_liczba_ts_trend
```

Jak widać wszystkie wartości się zgadzają.


ODTRENDOWANIE

Odjęcie od danych trendu

```{r}
plot(dane_4plus_Wiadomosci_liczba_ts-dane_4plus_Wiadomosci_liczba_ts_trend)
```

PRZECIETNA SEZONOWOŚĆ

```{r}
liczba_brak_miesiecy<-frequency (dane_4plus_Wiadomosci_liczba_ts)-length( dane_4plus_Wiadomosci_liczba_ts)%%frequency (dane_4plus_Wiadomosci_liczba_ts)
dane_4plus_Wiadomosci_liczba_ts_detrend<-dane_4plus_Wiadomosci_liczba_ts-dane_4plus_Wiadomosci_liczba_ts_trend
dane_4plus_Wiadomosci_liczba_ts_m<-matrix(data = c(dane_4plus_Wiadomosci_liczba_ts_detrend, rep(NA, liczba_brak_miesiecy) ), ncol = 12, nrow = 4, byrow = TRUE)
dane_4plus_Wiadomosci_liczba_ts_sezonowosc<-colMeans(dane_4plus_Wiadomosci_liczba_ts_m, na.rm = T)
dane_4plus_Wiadomosci_liczba_ts_sezonowosc<-dane_4plus_Wiadomosci_liczba_ts_sezonowosc-mean( dane_4plus_Wiadomosci_liczba_ts_sezonowosc) # to jest najwazniejszy krok -> przesuniecie sredniej sezonowosci do zera
dane_4plus_Wiadomosci_liczba_ts_sezonowosc<-ts( dane_4plus_Wiadomosci_liczba_ts_sezonowosc,  start = c(2013,1), end =c(2016,6) , frequency = 12 )


dane_4plus_Wiadomosci_liczba_ts_sezonowosc==decompose( dane_4plus_Wiadomosci_liczba_ts, type ="additive")[["seasonal"]]

plot(dane_4plus_Wiadomosci_liczba_ts_sezonowosc, ylab="oglądalność" , main="sezonowość")
```

SKŁADNIK LOSOWY

```{r}
filtr<-is.na( ma( dane_4plus_Wiadomosci_liczba_ts, order = 12 ))==FALSE
dane_4plus_Wiadomosci_liczba_ts_s.losowy<-dane_4plus_Wiadomosci_liczba_ts-dane_4plus_Wiadomosci_liczba_ts_trend-dane_4plus_Wiadomosci_liczba_ts_sezonowosc
dane_4plus_Wiadomosci_liczba_ts_s.losowy==decompose( dane_4plus_Wiadomosci_liczba_ts, type ="additive")[["random"]] # brak zgodnosci wynika z niewielkiej niedokladnosci 

plot( dane_4plus_Wiadomosci_liczba_ts_s.losowy)
```

Wygląda na to, że wariancja w czasie się zmienia. W ogóle dziwne rzeczy dzieją się 

ŁĄCZENIE KOMPONENTÓW

```{r}
plot( dane_4plus_Wiadomosci_liczba_ts,   ylab="liczba widzów", xlab="data", lwd=2, ylim=c(0, max(dane_4plus_Wiadomosci_liczba_ts)))
lines(dane_4plus_Wiadomosci_liczba_ts_trend + dane_4plus_Wiadomosci_liczba_ts_sezonowosc + dane_4plus_Wiadomosci_liczba_ts_s.losowy , col="red", type="h", lwd=2)
```

Podsumowując: 

Wawiancja w czasie raczej jest niezmienna.
Dekompozycja przy pomocy modelu addytywnego jest wystarczająca. 
Widać wyrażną sezonowość w ciągu roku - spadki oglądalności w lecie

```{r}
plot( window( dane_4plus_Wiadomosci_liczba_ts_sezonowosc, 2013, 2013.917), xlab="Miesiące", ylab="sezonowe zmiany oglądalności", main= "Sezonowość na \nprzykładzie roku 2013")
```

Widać również trend majelącej oglądalności

```{r}
plot( dane_4plus_Wiadomosci_liczba_ts, xlab="Miesiące", ylab="sezonowe zmiany oglądalności", main= "Trend",ylim=c(0, max(dane_4plus_Wiadomosci_liczba_ts)))
lines(dane_4plus_Wiadomosci_liczba_ts_trend,  col="red", type="o", lwd=2)
# lines(dane_4plus_Wiadomosci_liczba_ts_trend,  col="red", type="h", lwd=2)
```

1. widać pewien trend
2. widać sezonowośc 
3. nie widać obserwacji odstających 
4. wariancja wydaje się byc stała


### Regresja 

Dekompozycja, czy filtrowanie/wygładzanie danych pozwalają rozłożyć szereg czasowy na elementy, które ułatwiają nam opisywanie szeregu czasowego, ale nie dają nam narzędzi do opisu procesów, które w nim zachodzą. Do tego wykorzystamy więc zwykła regresję. Przy jej pomocy postaramy się określić jak "działa" szereg czasowy.

Do dyspozycji są dwie funkcje: 

__lm()__ - linear models
__lsfit()__ - least squares fit (czyli MNK - jeden z modeli liniowych)

Sprawa wydaje się prosta, bo trend jest raczej liniowy (nie przypomina paraboli) czyli prawdopodobnie wystarczy nam zwykły model liniowy.

Xt = a0+a1*Xt-1+et

gdzie: 

  * a0 -stała
  * a1 - parametr opóźnienia (poprzedniej obserwacji)
  * Xt-1 - opóźnienie o jeden (wartość zmiennej w okresie o jeden wcześniejszym)
  * et - składnik losowy
  
```{r}
plot( dane_4plus_Wiadomosci_liczba_ts,   ylab="liczba widzów", xlab="data", lwd=2, ylim=c(0, max(dane_4plus_Wiadomosci_liczba_ts)))
lines( as.numeric( time(dane_4plus_Wiadomosci_liczba_ts)),  lm(dane_4plus_Wiadomosci_liczba_ts~time(dane_4plus_Wiadomosci_liczba_ts))$fit, lwd=3, lty=2, col="red")
lines(dane_4plus_Wiadomosci_liczba_ts_trend,  col="navyblue", type="o", lwd=2)
```

Wykorzystaliśmy regresję liniową więc nasze oszacowanie objaśnia tylko trend, a nie wszystkie subtelne zmiany jakie zachodzą w poszczególnych sezonach. 

Możemy za to więcej powiedzieć o ogólnej tendencji jaka obserwujemy. 

```{r}
summary(lm(dane_4plus_Wiadomosci_liczba_ts~time(dane_4plus_Wiadomosci_liczba_ts)))
```

Co możemy powiedzieć o modelu:

  * parametry są istotne (dla poziomu ufności 0,95)
  * parametr czasu jest ujemny, czyli z czasem liczba widzów maleje - w naszym przypadku każdy miesiąc to przeciętnie `r round(184743*(1/12))` osób. 
  * Bardzo mała wartość R-kwadrat i skorygowanego R-kwadrat (0,1 i 0,07) - czyli model nie wyjaśnia wariancji (zmienności); widzimy to gołym okiem.

Model słabo przewiduje wartości zmiennej, ale nie sposób go tak od razu odrzucić. Wydaje się, że dobrze ilustruje trend. Niestety trudno to udowodnić inaczej niż na oko.  Tak czy inaczej mamy coś czego możemy się uchwycić. Dla prezentowanych danych zbudowaliśmy model liniowy, który zawiera informacje o przeciętnej miesięcznej zmianie jaka zachodzi w całym badanym czasie. 

Czas na model uwzględniający sezonowość

```{r}
plot( dane_4plus_Wiadomosci_liczba_ts,   ylab="liczba widzów", xlab="data", lwd=2, ylim=c(0, max(dane_4plus_Wiadomosci_liczba_ts)))
czas<-time(dane_4plus_Wiadomosci_liczba_ts)
lines( as.numeric( time(dane_4plus_Wiadomosci_liczba_ts)),  lm(dane_4plus_Wiadomosci_liczba_ts~czas+sin(2*pi*czas)+cos(2*pi*czas) )$fit, lwd=3, lty=2, col="red")
```

Przy pomocy transformacji Fourniera udało się uwzględnić zmiany zachodzące sezonowo:

```{r}
summary( lm(dane_4plus_Wiadomosci_liczba_ts~czas+sin(2*pi*czas)+cos(2*pi*czas) ))
```

Co możemy powiedzieć o modelu:

  * wszystkie parametry są istotne (dla poziomu ufności 0,95)
  * parametr czasu jest ujemny, czyli z czasem liczba widzów maleje - w naszym przypadku każdy miesiąc to przeciętnie `r round(184743*(1/12))` osób. 
  * prarametry sezonowości sin i cos są odpowiednio ujemnei dodatnie =
  * Wartość R-kwadrat i skorygowanego R-kwadrat są znacznie wyższe (0,82 i 0,81) - czyli model wyjaśnia wariancję (zmienności) całkiem dobrze; widzimy to gołym okiem.
  * Wartość P dla statystyki F to ~0 a więc można odrzucić hipotezę o nieistotności R (czyli calego modelu)

## 2. Wygładzanie wykładnicze

Czas na przewidywania - najciekawszą rzecz w szeregach czasowych. Istnieje kilka podejść do tego tematu. Zaczniemy od najprostrzych metod korzystających z wygladzania.

Przyjmiemy, że w każda obserwacja zależy w pewnym stopniu od tego co było wcześniej - od opóźnień z poprzednich okresów. Przy czym zakładamy, że im dawniej tym mniejszy wpływ na teraźniejszość. Wyjaśniamy bierzące wartości przy pomocy przeszłych. 

Xt=a0\*X(t-0)+a1\*X(t-1)+a2\*X(t-2)+a3*Xt-3+...

gdzie: 

ai= alfa(1-alfa)^i oraz 0<alfa<1

Ale wygładzanie wykładnicze powinno być stosowane tylko do szeregów czasowych bez trendu liniowego i sezonowości. Żeby obejść to utrudnienie używa się procedury __Holta–Wintersa__. Korzysta ona z trzech parametrów wygładzających: 

  * alfa (jak wyżej),
  * beta (trend)
  * gamma (zmiany sezonowe). 

```{r}
plot( dane_4plus_Wiadomosci_liczba_ts,   ylab="liczba widzów", xlab="data", lwd=2, ylim=c(0, max(dane_4plus_Wiadomosci_liczba_ts)))
lines( HoltWinters(dane_4plus_Wiadomosci_liczba_ts)$fitted[,"xhat"],col="red", lty=2, lwd=2)
HoltWinters(dane_4plus_Wiadomosci_liczba_ts)
```

W modelu uwzględniono opóźnienia z wykładniczymi wagami (alfa=1) i sezonowość (gamma=1) odrzucono za to trend (beta=0).

Czas na predykcję

```{r}
plot( dane_4plus_Wiadomosci_liczba_ts,   ylab="liczba widzów", xlab="data", lwd=2, ylim=c(0, max(dane_4plus_Wiadomosci_liczba_ts)), xlim=c(min(time( dane_4plus_Wiadomosci_liczba_ts)), 2017.917))
lines( predict( HoltWinters(dane_4plus_Wiadomosci_liczba_ts), n.ahead=12),col="navyblue", lty=4, lwd=3)
```

Mamy predykcjęna 12 miesięcy w przód do czerwca 2017. 


## 3. Model ARIMA - modelowanie wg wzoru Box-Jenkinsa

Czas na ulubiony model ekonometri ARIMA. Tą procedurę postępowania określa się mianem podejścia Boxa–Jenkinsa 

AR - auto regresion 
MR - moving average


Procedura składa się z następujących etapów:

  1. Identyfkacja modelu
  2. estymacja parametrów
  3. sprawdzenie diagnostyki

### Analiza autokorelacji i cześciowej autokorelacji

```{r}
sim.ar<-arima.sim(list(ar=c(0.4,0.4)),n=1000)
sim.ma<-arima.sim(list(ma=c(0.6,-0.4)),n=1000)
par(mfrow=c(2,2))
acf(sim.ar,main="ACF of AR(2) process")
acf(sim.ma,main="ACF of MA(2) process")
pacf(sim.ar,main="PACF of AR(2) process")
pacf(sim.ma,main="PACF of MA(2) process")
```



```{r}
par(mfrow=c(1,1))
data(LakeHuron)
plot(LakeHuron, ylim=c(0,max(LakeHuron)))
fit<-arima(LakeHuron,order=c(1,0,1))
tsdiag(fit)
```



```{r}

x <- 1:100
filter(x, rep(1, 3))

lag.plot(dane_4plus_Wiadomosci_liczba_ts, lags = 1, do.lines = FALSE, col="red", pch=19, diag.col = "blue")
```

Wartości teraźniejsze i przyszłe układają się mniej więcej na jednej lini. Możemy się więc spodziewać, że przy objaśnianiu istotne będą wartości opóźnione.

Model z jednym opóźnieniem AR(1)

Założenia:

  1. składnik losowy ma rozkład normalny z średnią równą zero i stałą wariancję,
  2. składnik losowy jest niezależny od wartości zmiennej objaśnianej

```{r}
dane_4plus_Wiadomosci_liczba_ts_ARIMA<-arima( dane_4plus_Wiadomosci_liczba_ts, order = c(1,0,0))
```

Dla modelu AR(1) element autoregresyjny 1 jest istotny. Czyli przy przewidywaniu oglądalności warto uwzględnić poprzedni miesiąc obserwacji.

```{r}
options(scipen=10)
plot( as.vector(dane_4plus_Wiadomosci_liczba_ts), as.vector(dane_4plus_Wiadomosci_liczba_ts_ARIMA$residuals) )
abline( h = 0, col="red")
```

Powyższy wykres pokazuje, że reszty są zależne od wartości zmiennej objaśnianej (oglądalności). To oznacza, że model nie spełnia założenia o niezależności reszt. Ten model nie wszystko tłumaczy.

Konieczne jest sprawdzenie korelacji między zmienną i jej opóźnieniami. Wykorzystana zostanie do tego funkcja autokorelacji (ACF - autocorrelation function)

```{r, eval=FALSE, include=FALSE, echo=FALSE}
################ SZEREG CZASOWY WIADOMOSCI TVP
# na czestosciach Wiadomosci
dane_4plus_Wiadomosci_czestosc_ts<-ts( data = dane_4plus$Wiadomosci_TVP1_procent, start = c(2013,1), frequency = 12)
cycle( dane_4plus_Wiadomosci_czestosc_ts)
aggregate( dane_4plus_Wiadomosci_czestosc_ts)
time( dane_4plus_Wiadomosci_czestosc_ts)
plot( dane_4plus_Wiadomosci_czestosc_ts, ylim=c(0, max(dane_4plus_Wiadomosci_czestosc_ts)))
abline( reg=lm( dane_4plus_Wiadomosci_czestosc_ts~time( dane_4plus_Wiadomosci_liczba_ts) ), col="red")
## Dekompozycja
decompose( dane_4plus_Wiadomosci_czestosc_ts) # dekompozycha
plot( decompose( dane_4plus_Wiadomosci_czestosc_ts))
plot( stl(dane_4plus_Wiadomosci_czestosc_ts, s.window="periodic"))
## Oszacowanie
plot(dane_4plus_Wiadomosci_czestosc_ts)
abline(lm(dane_4plus_Wiadomosci_czestosc_ts~time(dane_4plus_Wiadomosci_czestosc_ts)),col="red",lwd=2)
acf( dane_4plus_Wiadomosci_czestosc_ts)
## roznice na procentach
hist(diff( dane_4plus_Wiadomosci_czestosc_ts),col="red", breaks=20, ylim=c(0,40))
lines(density(diff( dane_4plus_Wiadomosci_czestosc_ts)),lwd=2)
### dodawanie oszacowanego rozkladu normalnego
mu<-mean(diff(dane_4plus_Wiadomosci_czestosc_ts))
sigma<-sd(diff(dane_4plus_Wiadomosci_czestosc_ts))
x<-seq(-0.04,0.04,length=100)
y<-dnorm(x,mu,sigma)
lines(x,y,lwd=2,col="blue")
### sprawdzanie przy pomocy funkcji "qqnorm" czy rzeczywiscie obserujemy rozklad normalny roznic
qqnorm(diff(dane_4plus_Wiadomosci_czestosc_ts)) # wykres
### sprawdzanie normalnosci przy pomocy testu kolmogorowa
x<-diff(dane_4plus_Wiadomosci_czestosc_ts)
ks.test(x,"pnorm",mean(x),sd(x))
### sprawdzanie normalnosci przy pomocy Shapiro?Test - lepsze rozwiazanie
shapiro.test(x) ### rozklad nie jest zbyt normalny ale troche przypomina wiec jest ok
# Linear Filtering of Time Series
plot(dane_4plus_Wiadomosci_czestosc_ts,type="l")
tui.1 <- filter(dane_4plus_Wiadomosci_czestosc_ts,filter=rep(1/5,5))
tui.2 <- filter(dane_4plus_Wiadomosci_czestosc_ts,filter=rep(1/25,25))
# tui.3 <- filter(dane_4plus_Wiadomosci_czestosc_ts,filter=rep(1/81,81))
lines(tui.1,col="red")
lines(tui.2,col="purple")
#lines(tui.3,col="blue")
# Decomposition of Time Series
plot(stl(dane_4plus_Wiadomosci_czestosc_ts, s.window="periodic")) # dekompozycja sezonowa
# Estimation 
plot( dane_4plus_Wiadomosci_czestosc_ts, ylim=c(0, max(dane_4plus_Wiadomosci_czestosc_ts)))
abline( reg=lm( dane_4plus_Wiadomosci_czestosc_ts~time( dane_4plus_Wiadomosci_liczba_ts) ), col="red")
summary( lm( dane_4plus_Wiadomosci_czestosc_ts~time( dane_4plus_Wiadomosci_liczba_ts)))
# Exponential Smoothing and Prediction of Time Series
plot(dane_4plus_Wiadomosci_czestosc_ts, lwd=2)
lines( fitted(HoltWinters(dane_4plus_Wiadomosci_czestosc_ts))[,1] ,col="red", lwd=2)
lines( fitted(HoltWinters(dane_4plus_Wiadomosci_czestosc_ts))[,2] ,col="green3", lwd=2)
# lines( fitted(HoltWinters(dane_4plus_Wiadomosci_czestosc_ts))[,4] ,col="green3", lwd=2)
lines(HoltWinters(dane_4plus_Wiadomosci_czestosc_ts)$fitted,col="red")
## predict
dane.hw<-HoltWinters(dane_4plus_Wiadomosci_czestosc_ts)
predict(dane.hw,n.ahead=12)
plot(dane_4plus_Wiadomosci_czestosc_ts, xlim=c(2013.0, 2017.15))
lines(predict(dane.hw,n.ahead=48),col="red")
#### predykcja
dane_4plus_Wiadomosci_czestosc_ts_HW<-HoltWinters(dane_4plus_Wiadomosci_czestosc_ts)
predict(dane_4plus_Wiadomosci_czestosc_ts_HW,n.ahead=12)

plot(dane_4plus_Wiadomosci_czestosc_ts,xlim=c(2013, 2018), lwd=2)
lines(predict( dane_4plus_Wiadomosci_czestosc_ts_HW, n.ahead=12), col="red", lwd=2)

### UWAGA !!! MODEL BAZRDZO ZLE PRZEWIDUJE PRZYSZLOSC -> TO JEST WINA OSTATNIEGO ZALAMANIA

# ARIMA–Models
## autocorrelations and partial autocorrelations
## Przyklad ARIMA
sim.ar<-arima.sim(list(ar=c(0.4,0.4)),n=1000)
sim.ma<-arima.sim(list(ma=c(0.6,-0.4)),n=1000)
par(mfrow=c(2,2))
acf(sim.ar,main="ACF of AR(2) process")
acf(sim.ma,main="ACF of MA(2) process")
pacf(sim.ar,main="PACF of AR(2) process")
pacf(sim.ma,main="PACF of MA(2) process")

# ARIMA–Models

fit<-arima( dane_4plus_Wiadomosci_czestosc_ts, order=c(1,0,1))
tsdiag(fit)
Box.test(fit$residuals,lag=2)

# na liczebnosciach FAKTY
dane_4plus_Fakty_liczba_ts<-ts( data = dane_4plus$Fakty_TVN, start = c(2013,1), frequency = 12)
cycle( dane_4plus_Fakty_liczba_ts)
aggregate( dane_4plus_Fakty_liczba_ts)
time( dane_4plus_Fakty_liczba_ts)
plot( dane_4plus_Fakty_liczba_ts)
abline( reg=lm( dane_4plus_Fakty_liczba_ts~time( dane_4plus_Fakty_liczba_ts) ))
decompose( dane_4plus_Fakty_liczba_ts)
plot( decompose( dane_4plus_Fakty_liczba_ts))
# porownanie 
ts.plot( dane_4plus_Fakty_liczba_ts, dane_4plus_Wiadomosci_liczba_ts, col=c("blue", "red") )

```






# Wykresy dla danych 16-49

```{r}
##############
## udzial w widowni
##############
png('TELEMETRIA_wykresy/16_49_udzial.png',  res = 200, width = 20, height = 10, units = "cm") #bg = "white", 
ggplot(ndane_16_49[ grep("procent",ndane_16_49$program),], aes(x=miesiac , y=ogladalnosc, group=program, color=program,size=1))+
  geom_line()+
  theme(axis.text.x = element_text(angle = 90, hjust = 1))+
  labs(title = "Odsetek widzów w grupie 16-49")
dev.off()
##############
## liczebnosc widowni
##############
png('TELEMETRIA_wykresy/16_49_liczba.png',  res = 200, width = 20, height = 10, units = "cm") #bg = "white", 
ggplot(ndane_16_49[ !(1:dim(ndane_16_49)[1]) %in% grep("procent", ndane_16_49$program),], aes(x=miesiac , y=ogladalnosc, group=program, color=program))+
  geom_line()+
  theme(axis.text.x = element_text(angle = 90, hjust = 1))+
  labs(title = "Liczba widzów w grupie 16-49")
dev.off()
##############
## ROZNICE - zmiany rok do roku i procentowe rok do roku
##############
rdane_16_49<-as.matrix(dane_16_49[, !(1:dim(dane_16_49)[2]) %in% grep("procent|miesiac", colnames(dane_16_49) )])
rdane_16_49<- data.frame(  diff( rdane_16_49 ,lag = 12) / rdane_16_49[1:(dim( rdane_16_49 )[1]-12) ,  ]      )
rdane_16_49$miesiac<-dane_16_49$miesiac[ (dim(dane_16_49)[1]-dim(rdane_16_49)[1]+1):dim(dane_16_49)[1]]
nrdane_16_49 <- melt(rdane_16_49,id=c("miesiac") ) # zmiana postaci danych
nrdane_16_49$variable<-as.character(nrdane_16_49$variable)
colnames(nrdane_16_49)<-c("miesiac", "program","ogladalnosc")
##############
## wykres roznic
##############
png('TELEMETRIA_wykresy/16-49_roznica.png',  res = 200, width = 20, height = 10, units = "cm") #bg = "white", 
ggplot(nrdane_16_49, aes(x=miesiac , y=ogladalnosc, group=program, color=program))+
  geom_line()+
  geom_hline(aes(yintercept=0))+
  theme(axis.text.x = element_text(angle = 90, hjust = 1))+
  labs(title = "Procentowe różnice rok do roku w grupie widzów 16-49")
dev.off()
```
